{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15573f20-5120-471e-8e37-319c4997c58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import pandas as pd\n",
    "import glob2 as glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140fb949-7dd0-483d-893b-04f384ab20cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd486c41-0168-4678-b090-29bfe8d19305",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### from DeepSlice plane_alignment.py and depth_estimation.py \n",
    "# https://github.com/PolarBean/DeepSlice/DeepSlice/DeepSlice/coord_post_processing/depth_estimation.py \n",
    "# https://github.com/PolarBean/DeepSlice/DeepSlice/coord_post_processing/plane_alignment_functions/plane_alignment.py\n",
    "\n",
    "from statistics import mean\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "\n",
    "def find_plane_equation(plane):\n",
    "    \"\"\"\n",
    "    Finds the plane equation of a plane\n",
    "    :param plane: the plane to find the equation of\n",
    "    :type plane: :any:`numpy.ndarray`\n",
    "    :returns: the normal vector of the plane and the constant k\n",
    "    :rtype: :any:`numpy.ndarray`, float\n",
    "    \"\"\"\n",
    "    a, b, c = (\n",
    "        np.array(plane[0:3], dtype=np.float64),\n",
    "        np.array(plane[3:6], dtype=np.float64),\n",
    "        np.array(plane[6:9], dtype=np.float64),\n",
    "    )\n",
    "    cross = np.cross(b, c)\n",
    "    cross /= 9\n",
    "    k = -((a[0] * cross[0]) + (a[1] * cross[1]) + (a[2] * cross[2]))\n",
    "    return (cross, k)\n",
    "\n",
    "def calculate_brain_center_depth(section):\n",
    "    \"\"\"\n",
    "    Calculates the depth of the brain center for a given section\n",
    "\n",
    "    :param section: the section coordinates as an array consisting of Oxyz,Uxyz,Vxyz \n",
    "    :type section: np.array\n",
    "    :return: the depth of the brain center\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    cross, k = find_plane_equation(section)\n",
    "    translated_volume = np.array((456, 0, 320))\n",
    "    linear_point = (\n",
    "        ((translated_volume[0] / 2) * cross[0])\n",
    "        + ((translated_volume[2] / 2) * cross[2])\n",
    "    ) + k\n",
    "    depth = -(linear_point / cross[1])\n",
    "    return depth\n",
    "\n",
    "\n",
    "def calculate_brain_center_depths(predictions):\n",
    "    \"\"\"\n",
    "    Calculates the depths of the brain center for a series of predictions\n",
    "    \n",
    "    :param predictions: dataframe of predictions\n",
    "    :type predictions: pandas.DataFrame\n",
    "    :return: a list of depths\n",
    "    :rtype: list[float]\n",
    "    \"\"\"\n",
    "    depths = []\n",
    "    for prediction in predictions[\n",
    "        [\"ox\", \"oy\", \"oz\", \"ux\", \"uy\", \"uz\", \"vx\", \"vy\", \"vz\"]\n",
    "    ].values:\n",
    "        depths.append(calculate_brain_center_depth(prediction))\n",
    "    return depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e55bb84-803d-4263-9588-e1a041be6326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_depths(reference_df, sample_df):\n",
    "    # DeepSlice_wDepth = interpolate_depths(DeepSlice_PrV, DeepSlice_rawOutput)\n",
    "    \n",
    "    lookup_df = pd.DataFrame(data= {'depths': reference_df[\"depths\"][1:397], 'vole_depths':reference_df[\"vole_depths\"][1:397]})\n",
    "    lookup_df = lookup_df.sort_values(by='depths', ascending=True)\n",
    "    min_vals = [np.min(lookup_df[\"depths\"]),np.min(lookup_df[\"vole_depths\"])]\n",
    "    max_vals = [np.max(lookup_df[\"depths\"]),np.max(lookup_df[\"vole_depths\"])]\n",
    "    \n",
    "    input_df = sample_df.copy()\n",
    "    depths_list = []\n",
    "    vole_depths_list = []\n",
    "    \n",
    "    for alignment in input_df.iterrows():\n",
    "        m = alignment[1][[\"ox\", \"oy\", \"oz\", \"ux\", \"uy\", \"uz\", \"vx\", \"vy\", \"vz\"]].values.astype(np.float64)\n",
    "        depth = calculate_brain_center_depth(m)\n",
    "        \n",
    "        if depth < min_vals[0]: \n",
    "            vole_depth = min_vals[1] # values more posterior than end of look-up table are matched with last value of look-up table\n",
    "            print('depth = ' + str(depth) + ', which is outside of range. Matched with nearest reference value.')\n",
    "        elif depth > max_vals[0]: \n",
    "            vole_depth = max_vals[1] # values more anterior than start of look-up table are matched with first value of look-up table\n",
    "            print('depth = ' + str(depth) + ', which is outside of range. Matched with nearest reference value.')\n",
    "        else: vole_depth = np.interp(depth, lookup_df[\"depths\"], lookup_df[\"vole_depths\"])\n",
    "\n",
    "        depths_list.append(depth)\n",
    "        vole_depths_list.append(vole_depth)\n",
    "    \n",
    "    input_df.insert(12, \"depths\",depths_list,False)\n",
    "    input_df.insert(13, \"vole_depths\",vole_depths_list,False)\n",
    "   \n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4553c44-3bbd-4f2a-b748-bb1e51c3e1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_size_center(reference_df, section):\n",
    "    # o_adj, u_adj, v_adj = adjust_size_center(DeepSlice_PrV, alignment[1][[\"ox\", \"oy\", \"oz\", \"ux\", \"uy\", \"uz\", \"vx\", \"vy\", \"vz\",\"vole_depths\"]])\n",
    "    \n",
    "    ######################################## Match section with relevant reference section ##################################################################\n",
    "\n",
    "    lookup_df = pd.DataFrame(data= {'ox':reference_df[\"ox\"][1:397],'oy':reference_df[\"oy\"][1:397],'oz':reference_df[\"oz\"][1:397], \n",
    "                                'ux':reference_df[\"ux\"][1:397],'uy':reference_df[\"uy\"][1:397],'uz':reference_df[\"uz\"][1:397],\n",
    "                                'vx':reference_df[\"vx\"][1:397],'vy':reference_df[\"vy\"][1:397],'vz':reference_df[\"vz\"][1:397],\n",
    "                                'vole_depths':reference_df[\"vole_depths\"][1:397]})\n",
    "    lookup_df = lookup_df.sort_values(by='vole_depths', ascending=True)\n",
    "\n",
    "    sample_depth = section[\"vole_depths\"]\n",
    "\n",
    "    o_ref = [np.interp(sample_depth, lookup_df[\"vole_depths\"], lookup_df[\"ox\"]),\n",
    "                   np.interp(sample_depth, lookup_df[\"vole_depths\"], lookup_df[\"oy\"]),\n",
    "                   np.interp(sample_depth, lookup_df[\"vole_depths\"], lookup_df[\"oz\"])]\n",
    "    u_ref = [np.interp(sample_depth, lookup_df[\"vole_depths\"], lookup_df[\"ux\"]),\n",
    "                   np.interp(sample_depth, lookup_df[\"vole_depths\"], lookup_df[\"uy\"]),\n",
    "                   np.interp(sample_depth, lookup_df[\"vole_depths\"], lookup_df[\"uz\"])]\n",
    "    v_ref = [np.interp(sample_depth, lookup_df[\"vole_depths\"], lookup_df[\"vx\"]),\n",
    "             np.interp(sample_depth, lookup_df[\"vole_depths\"], lookup_df[\"vy\"]),\n",
    "             np.interp(sample_depth, lookup_df[\"vole_depths\"], lookup_df[\"vz\"])]\n",
    "\n",
    "    o_sample = section[[\"ox\",\"oy\",\"oz\"]].values.astype(np.float64)\n",
    "    u_sample = section[[\"ux\",\"uy\",\"uz\"]].values.astype(np.float64)\n",
    "    v_sample = section[[\"vx\",\"vy\",\"vz\"]].values.astype(np.float64)\n",
    "\n",
    "    ####################################################### Move centroid and adjust scale ##################################################################\n",
    "\n",
    "    centroid_ref = centroid_from_vectors(o_ref,u_ref,v_ref) # finds rough center of reference section (in mouse vx)\n",
    "    centroid_sample = centroid_from_vectors(o_sample,u_sample,v_sample) # finds rough center of sample section (in mouse vx)\n",
    "\n",
    "    width_ref = magnitude_3d(u_ref) # finds width of reference (in mouse vx)\n",
    "    width_sample = magnitude_3d(u_sample) # finds width of sample (in mouse vx)\n",
    "\n",
    "    height_ref = magnitude_3d(v_ref) # finds height of reference (in mouse vx)\n",
    "    height_sample = magnitude_3d(v_sample) # finds height of sample (in mouse vx)\n",
    "\n",
    "    centroid_dif = [s-r for s,r in zip(centroid_sample,centroid_ref)] # finds difference between sample and reference centroid (in mouse vx)\n",
    "    adj_centr_dif = [(centroid_dif[0]*417/width_ref),0,(centroid_dif[2]*350/height_ref)] # scales the x and z components to vole dimensions\n",
    "    centroid_ref_vole = [417/2, 0, 350/2] # center of reference section in vole space\n",
    "    centroid_sample_vole = [r+dif for r,dif in zip(centroid_ref_vole,adj_centr_dif)] # uses scaled difference vector to set centroid of section\n",
    "\n",
    "    adjusted_width = width_sample*417/width_ref # scales the sample width to vole dimensions\n",
    "    adjusted_height = height_sample*350/height_ref # scales the sample height to vole dimensions\n",
    "\n",
    "    o_adj = [(centroid_sample_vole[0]+(adjusted_width/2)),sample_depth,(centroid_sample_vole[2]+(adjusted_height/2))] # new o based on w/h and centroid (in vole vx)\n",
    "    u_adj = [-adjusted_width,0,0] # new u from adjusted width (vole vx)\n",
    "    v_adj = [0,0,-adjusted_height] # new v from adjusted height (vole vx)\n",
    "\n",
    "    ##################################################### Adjust angles of U and V, find new O ##############################################################\n",
    "\n",
    "    u_sample_flat = [u_sample[0],u_sample[2]] # flattened vector u from sample section\n",
    "    v_sample_flat = [v_sample[0],v_sample[2]] # flattened vector v from sample section\n",
    "    u_ref_flat = [u_ref[0],u_ref[2]] # flattened vector u from reference section\n",
    "    v_ref_flat = [v_ref[0],v_ref[2]] # flattened vector v from reference section\n",
    "\n",
    "    ### find new ux/z and vx/z\n",
    "    u_rot,angle_u_dif = uv_rotation(u_sample_flat,u_ref_flat,adjusted_width,'u')\n",
    "    v_rot,angle_v_dif = uv_rotation(v_sample_flat,v_ref_flat,adjusted_height,'v')\n",
    "    \n",
    "    ### find new ox, oz\n",
    "    o_rot = o_rotation(o_adj, angle_v_dif, centroid_ref_vole)\n",
    "\n",
    "    \n",
    "    return o_rot,u_rot,v_rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "238c2eb0-6425-4471-b02a-a04fccc3b8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uv_rotation(sample_flat,ref_flat,adj_length,u_or_v):\n",
    "    # u_rot = uv_rotation(u_sample_flat,u_ref_flat,adjusted_width,'u')\n",
    "    \n",
    "    angle_sample = angle_xz(sample_flat,u_or_v,'rad') # calculate original angle of sample u in radians\n",
    "    angle_ref = angle_xz(ref_flat,u_or_v,'rad') # calculate original angle of reference u in radians\n",
    "    angle_dif = angle_ref-angle_sample\n",
    "    \n",
    "    if 'u' in u_or_v.lower():\n",
    "        x_rot = adj_length * np.cos(angle_dif) # find rotated u (adjusted u angle with scaled width)\n",
    "        z_rot = adj_length * np.sin(angle_dif) \n",
    "        vector_rot = [-x_rot,0,z_rot]\n",
    "    elif 'v' in u_or_v.lower():     \n",
    "        x_rot = adj_length * np.sin(angle_dif) # find rotated v (adjusted v angle with scaled height)\n",
    "        z_rot = adj_length * np.cos(angle_dif)\n",
    "        vector_rot = [x_rot,0,-z_rot]\n",
    "    return vector_rot, angle_dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43cba1e3-ea9a-4121-be7f-210d55e2a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def o_rotation(o_adj, angle_v_dif, centroid):\n",
    "    cO = [O-c for O,c in zip(o_adj,centroid)]\n",
    "    cO_flat = [cO[0], cO[2]]\n",
    "    len_cO = magnitude_3d([cO[0], 0, cO[2]])\n",
    "    cO_angle = np.arctan(cO_flat[1]/cO_flat[0])*180/np.pi\n",
    "\n",
    "    new_opposite_angle = (90-cO_angle) - (angle_v_dif * 180/np.pi)\n",
    "\n",
    "    delta_x_rot = np.sin((new_opposite_angle * np.pi/180)) * len_cO\n",
    "    delta_z_rot = np.cos((new_opposite_angle * np.pi/180)) * len_cO\n",
    "    cO_rot = [delta_x_rot, 0, delta_z_rot]\n",
    "\n",
    "    o_rot = [cO_rot[0] + centroid[0], cO_rot[1] + o_adj[1], cO_rot[2]+centroid[2]]\n",
    "    \n",
    "    return o_rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9f282ec-4cce-4de3-9553-9a4aa18ad636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_xz(vector,u_or_v,units):\n",
    "    #e.g., angle_u = angle_xz(u_sample_flat,'u','degrees')\n",
    "    \n",
    "    if len(vector) == 2:\n",
    "        x_val = vector[0]\n",
    "        z_val = vector[1]\n",
    "    elif len(vector) == 3:\n",
    "        x_val = vector[0]\n",
    "        z_val = vector[2]\n",
    "    else: print('Error: vector should either be formatted as [x,y,z] or [x,z]')\n",
    "    \n",
    "    if u_or_v == 'u': angle_rad = np.arctan(z_val/x_val)\n",
    "    elif u_or_v == 'v': angle_rad = np.arctan(x_val/z_val)\n",
    "    else: print(\"Error: must specify 'u' or 'v'\")\n",
    "    \n",
    "    if 'deg' in units.lower(): angle = angle_rad*180/np.pi\n",
    "    elif 'rad' in units.lower(): angle = angle_rad\n",
    "    else: print(\"Error: units must contain 'rad' or 'deg'\")\n",
    "\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "edf70db5-0f17-4ebc-b7b7-6cec3da76fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitute_PrVRef_values(sample_df, o_list,u_list,v_list):\n",
    "    # DeepSlice_processed = substitute_PrVRef_values(DeepSlice_wDepth,o_adj,u_adj,v_adj)\n",
    "    \n",
    "    input_df = sample_df.copy()\n",
    "    output_df = pd.DataFrame().reindex_like(input_df.filter(['Filenames', 'ox','oy', 'oz', 'ux', 'uy', 'uz', 'vx', 'vy', 'vz', 'width', 'height','vole_depths'], axis=1))\n",
    "\n",
    "    for i in range(len(output_df)): # Copy filenames, width, and height from the raw output\n",
    "        output_df.loc[i,\"Filenames\"] = input_df.loc[i,\"Filenames\"]\n",
    "        output_df.loc[i,\"width\"] = input_df.loc[i,\"width\"]\n",
    "        output_df.loc[i,\"height\"] = input_df.loc[i,\"height\"]\n",
    "        output_df.loc[i,\"vole_depths\"] = input_df.loc[i,\"vole_depths\"]\n",
    "\n",
    "        o_adj = o_list[i]\n",
    "        u_adj = u_list[i]\n",
    "        v_adj = v_list[i]\n",
    "        \n",
    "        output_df.loc[i,\"ox\"] = o_adj[0]\n",
    "        output_df.loc[i,\"oy\"] = o_adj[1]\n",
    "        output_df.loc[i,\"oz\"] = o_adj[2]\n",
    "\n",
    "        output_df.loc[i,\"ux\"] = u_adj[0]\n",
    "        output_df.loc[i,\"uy\"] = 0\n",
    "        output_df.loc[i,\"uz\"] = u_adj[2]\n",
    "\n",
    "        output_df.loc[i,\"vx\"] = v_adj[0]\n",
    "        output_df.loc[i,\"vy\"] = 0\n",
    "        output_df.loc[i,\"vz\"] = v_adj[2]\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71c7b179-f8ff-4628-a424-2aabea9a80d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid_from_vectors(o, u, v):\n",
    "    # eg. centroid = centroid_from_vectors([ox, oy, oz], [ux, uy, uz], [vx, vy, vz])\n",
    "    \n",
    "    top_left_corner = o\n",
    "    top_right_corner = list(map(sum, zip(o,u)))\n",
    "    bottom_left_corner = list(map(sum, zip(o,v)))\n",
    "    bottom_right_corner = list(map(sum, zip(o,u,v)))\n",
    "    \n",
    "    centroid = [(top_right_corner[0]+bottom_left_corner[0])/2, (top_right_corner[1]+bottom_left_corner[1])/2,(top_right_corner[2]+bottom_left_corner[2])/2]\n",
    "    \n",
    "    return centroid #depth is centroid y component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d058647c-4628-4eda-bb31-03e91b215ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def magnitude_3d(a):\n",
    "    \n",
    "    magnitude = np.sqrt(np.sum([a[0]**2, a[1]**2, a[2]**2]))\n",
    "    \n",
    "    return magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eef4fc8a-68ab-4a9c-a4b6-3f0a1bd69a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### from DeepSlice QuickNII_functions.py (https://github.com/PolarBean/DeepSlice/DeepSlice/read_and_write/)\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def write_QuickNII_XML(df: pd.DataFrame, filename: str, aligner: str) -> None: # Note: aligner is DeepSlice version (JS)\n",
    "    \"\"\"\n",
    "    Converts a pandas DataFrame to a quickNII compatible XML\n",
    "    \"\"\"\n",
    "    df_temp = df.copy()\n",
    "    if \"nr\" not in df_temp.columns:\n",
    "        df_temp[\"nr\"] = np.arange(len(df_temp)) + 1\n",
    "    df_temp[[\"ox\", \"oy\", \"oz\", \"ux\", \"uy\", \"uz\", \"vx\", \"vy\", \"vz\", \"nr\"]] = df[\n",
    "        [\"ox\", \"oy\", \"oz\", \"ux\", \"uy\", \"uz\", \"vx\", \"vy\", \"vz\", \"nr\"]\n",
    "    ].astype(str)\n",
    "    out_df = pd.DataFrame(\n",
    "        {\n",
    "            \"anchoring\": \"ox=\"\n",
    "            + (df_temp.ox)\n",
    "            + \"&oy=\"\n",
    "            + (df_temp.oy)\n",
    "            + \"&oz=\"\n",
    "            + (df_temp.oz)\n",
    "            + \"&ux=\"\n",
    "            + (df_temp.ux)\n",
    "            + \"&uy=\"\n",
    "            + (df_temp.uy)\n",
    "            + \"&uz=\"\n",
    "            + (df_temp.uz)\n",
    "            + \"&vx=\"\n",
    "            + (df_temp.vx)\n",
    "            + \"&vy=\"\n",
    "            + (df_temp.vy)\n",
    "            + \"&vz=\"\n",
    "            + (df_temp.vz),\n",
    "            \"filename\": df_temp.Filenames,\n",
    "            \"height\": df_temp.height,\n",
    "            \"width\": df_temp.width,\n",
    "            \"nr\": df_temp.nr,\n",
    "        }\n",
    "    )\n",
    "    print(f\"saving to {filename}.xml\")\n",
    "\n",
    "    out_df.to_xml(\n",
    "        filename + \".xml\",\n",
    "        index=False,\n",
    "        root_name=\"series\",\n",
    "        row_name=\"slice\",\n",
    "        attr_cols=list(out_df.columns),\n",
    "        namespaces={\n",
    "            \"first\": df_temp.nr.values[0],\n",
    "            \"last\": df_temp.nr.values[-1],\n",
    "            \"name\": filename,\n",
    "            \"aligner\": aligner,\n",
    "            \"\": \"\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "def read_QuickNII_XML(filename: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts a QuickNII XML to a pandas dataframe\n",
    "\n",
    "    :param xml: The path to the QuickNII XML\n",
    "    :type xml: str\n",
    "    :return: A pandas dataframe\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "    df = pd.read_xml(filename)\n",
    "    # split the anchoring string into separate columns\n",
    "    anchoring = df.anchoring.str.split(\"&\", expand=True).values\n",
    "    # lambda function to remove non_numeric characters besides '.', we need this as all the 'ox=' etc is still in the strings\n",
    "    strip = lambda x: \"\".join(\n",
    "        c for c in x if c.isdigit() or c == \".\" or c == \"-\" or c == \"e\"\n",
    "    )\n",
    "    ##vectorise the lambda function and apply it to all elements\n",
    "    anchoring = np.vectorize(strip)(anchoring)\n",
    "    anchoring = anchoring.astype(np.float64)\n",
    "    out_df = pd.DataFrame({\"Filenames\": df.filename})\n",
    "    out_df[[\"ox\", \"oy\", \"oz\", \"ux\", \"uy\", \"uz\", \"vx\", \"vy\", \"vz\"]] = anchoring\n",
    "    return out_df\n",
    "\n",
    "\n",
    "def write_QUINT_JSON(\n",
    "    df: pd.DataFrame, filename: str, aligner: str, target: str \n",
    ") -> None: # Note: target is name of cutlas file (JS)\n",
    "    \"\"\"\n",
    "    Converts a pandas DataFrame to a QUINT (QuickNII, Visualign, & Nutil) compatible JSON\n",
    "    \"\"\"\n",
    "    if \"nr\" not in df.columns:\n",
    "        df[\"nr\"] = np.arange(len(df)) + 1\n",
    "    alignments = df[[\"ox\", \"oy\", \"oz\", \"ux\", \"uy\", \"uz\", \"vx\", \"vy\", \"vz\"]].values\n",
    "    if \"markers\" in df.columns:\n",
    "        markers = df.markers.values\n",
    "    else:\n",
    "        markers = [[]] * len(df)\n",
    "    #print(len(markers)) commented out by JS\n",
    "    alignment_metadata = [\n",
    "        {\n",
    "            \"filename\": fn,\n",
    "            \"anchoring\": list(alignment),\n",
    "            \"height\": h,\n",
    "            \"width\": w,\n",
    "            \"nr\": nr,\n",
    "            \"markers\": marker[0] if len(marker)> 0 else [],\n",
    "        }\n",
    "        for fn, alignment, nr, marker, h, w in zip(\n",
    "            df.Filenames, alignments, df.nr, markers, df.height, df.width\n",
    "        )\n",
    "    ]\n",
    "    QUINT_json = {\n",
    "        \"name\": \"\",\n",
    "        \"target\": target,\n",
    "        \"aligner\": aligner,\n",
    "        \"slices\": alignment_metadata,\n",
    "    }\n",
    "    print(f\"saving to {filename}.json\")\n",
    "    with open(filename + \".json\", \"w\") as f:\n",
    "        json.dump(QUINT_json, f)\n",
    "    with open(filename + \".json\", \"w\") as outfile:\n",
    "        json.dump(QUINT_json, outfile)\n",
    "\n",
    "\n",
    "def read_QUINT_JSON(filename: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts a QUINT JSON to a pandas dataframe\n",
    "    \n",
    "    :param json: The path to the QUINT JSON\n",
    "    :type json: str\n",
    "    :return: A pandas dataframe\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "    with open(filename, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    sections = data[\"slices\"]\n",
    "    target_volume = data[\"target\"]\n",
    "    alignments = [\n",
    "        row[\"anchoring\"] if \"anchoring\" in row else 9 * [np.nan] for row in sections\n",
    "    ]\n",
    "    height = [row[\"height\"] if \"height\" in row else [] for row in sections]\n",
    "    width = [row[\"width\"] if \"width\" in row else [] for row in sections]\n",
    "    filenames = [row[\"filename\"] if \"filename\" in row else [] for row in sections]\n",
    "    section_numbers = [row[\"nr\"] if \"nr\" in row else [] for row in sections]\n",
    "    markers = [row[\"markers\"] if \"markers\" in row else [] for row in sections]\n",
    "    df = pd.DataFrame({\"Filenames\": filenames, \"nr\": section_numbers})\n",
    "    df[[\"ox\", \"oy\", \"oz\", \"ux\", \"uy\", \"uz\", \"vx\", \"vy\", \"vz\"]] = alignments\n",
    "    df[\"markers\"] = markers\n",
    "    df[\"height\"] = height\n",
    "    df[\"width\"] = width\n",
    "    return df, target_volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f29f78-f0b6-4d8a-883f-ac0385c3c533",
   "metadata": {},
   "source": [
    "## Walkthrough Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fef22e2-0f03-459f-89d8-77d279fa6954",
   "metadata": {},
   "source": [
    "* Start with the image(s) you will use for alignment and registration. Typically this will be autofluorescence, brightfield, or DAPI. DeepSlice automatically downsamples images to 299 x 299 pixels, so everything goes smoother if you downsample your image to a maximum dimension of 300. While DeepSlice can work with any image format, QuickNII can only do png or jpg, so you will need to convert format too (https://www.deepslice.com.au/guide). **If you will need to rotate your sections to make them roughly level (eg. < +/-30˚ tilted), you will need to adjust your stained images as well.\n",
    "    * Open your both autofluoresence and stained images in Fiji\n",
    "    * Rotate your sections as needed to be roughly horizontal. Make sure you do the same to both stained and background channels of the same section.\n",
    "        * Image > Transform >\n",
    "            * Rotate 90 Degrees Right/Left: This should be sufficient for most sections.\n",
    "            * Rotate...: If your sample is more crooked, this may be necessary to ensure DeepSlice perform adequately. **Make sure whatever you do to the background channel of a section, you also do to the section you stained (and vice versa)**\n",
    "    * Scale your background image to an appropriate size for DeepSlice.\n",
    "        * Image > Scale\n",
    "        * Set Width (pixels): 300\n",
    "        * Leave \"Average when downsizing\" and \"Create new window\" checked\n",
    "        * You may also rename your image in the Title box at the bottom\n",
    "    * File > Save As > PNG\n",
    "* Navigate to DeepSlice on your browser (https://www.deepslice.com.au/)\n",
    "    * Choose Files: upload your images\n",
    "        * If you are analyzing multiple animals, run them through DeepSlice separately\n",
    "        * If you get error messages, try running your samples in smaller batches\n",
    "    * Choose a Species: Mouse\n",
    "    * Angle Integration: [x]\n",
    "    * Use Cutting Index (Section Numbers): [ ] or [x]\n",
    "        * Note: this requires 3-digit numbers at the end of the filename. Spacing between numbers should reflect spacing between sections (e.g. 003, 006, etc.)\n",
    "    * Model Ensemble [x]\n",
    "    * Use my data to improve DeepSlice [x]\n",
    "* Review the output from DeepSlice by toggling the Opacity bar and clicking between youur sections (< Previous | Next > )\n",
    "    * Export the CSV if you are continuing and planning to use the Vole atlas\n",
    "    * Export the XML and JSON files if you are sticking with the mouse atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "985ec31a-5eda-4a0b-8b81-aea35b980d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Paths\n",
    "path_to_images = 'DeepSlice_PrV_adjustment/Sample_Images/'\n",
    "path_to_PrV_Reference = 'DeepSlice_PrV_adjustment/PrV_Reference/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68b60bf4-4764-4ab4-90d3-9825eb0a161b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filenames</th>\n",
       "      <th>ox</th>\n",
       "      <th>oy</th>\n",
       "      <th>oz</th>\n",
       "      <th>ux</th>\n",
       "      <th>uy</th>\n",
       "      <th>uz</th>\n",
       "      <th>vx</th>\n",
       "      <th>vy</th>\n",
       "      <th>vz</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E1572_10x_stitch_CH2-downsized.png</td>\n",
       "      <td>439.274002</td>\n",
       "      <td>283.198959</td>\n",
       "      <td>350.450287</td>\n",
       "      <td>-475.870483</td>\n",
       "      <td>-12.129413</td>\n",
       "      <td>-42.959049</td>\n",
       "      <td>25.740665</td>\n",
       "      <td>-25.492914</td>\n",
       "      <td>-363.919922</td>\n",
       "      <td>300</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Filenames          ox          oy          oz  \\\n",
       "0  E1572_10x_stitch_CH2-downsized.png  439.274002  283.198959  350.450287   \n",
       "\n",
       "           ux         uy         uz         vx         vy          vz  width  \\\n",
       "0 -475.870483 -12.129413 -42.959049  25.740665 -25.492914 -363.919922    300   \n",
       "\n",
       "   height  \n",
       "0     205  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import your csv as a Pandas DataFrame\n",
    "filename = path_to_images + \"Sample_10x_CH2_DeepSlice_raw.csv\"\n",
    "DeepSlice_rawOutput = pd.read_csv(filename, header=0)\n",
    "DeepSlice_rawOutput.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b0f9974-3457-4981-bd73-529200088af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filenames</th>\n",
       "      <th>ox</th>\n",
       "      <th>oy</th>\n",
       "      <th>oz</th>\n",
       "      <th>ux</th>\n",
       "      <th>uy</th>\n",
       "      <th>uz</th>\n",
       "      <th>vx</th>\n",
       "      <th>vy</th>\n",
       "      <th>vz</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>nr</th>\n",
       "      <th>vole_depths</th>\n",
       "      <th>depths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>png_downsampled_xy000.png</td>\n",
       "      <td>494.408054</td>\n",
       "      <td>334.373789</td>\n",
       "      <td>388.076803</td>\n",
       "      <td>-602.175069</td>\n",
       "      <td>-0.052537</td>\n",
       "      <td>14.651203</td>\n",
       "      <td>-10.271103</td>\n",
       "      <td>16.361331</td>\n",
       "      <td>-478.207237</td>\n",
       "      <td>360</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>415</td>\n",
       "      <td>342.371957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>png_downsampled_xy001.png</td>\n",
       "      <td>494.301132</td>\n",
       "      <td>481.155443</td>\n",
       "      <td>414.635889</td>\n",
       "      <td>-584.046991</td>\n",
       "      <td>-0.133129</td>\n",
       "      <td>16.613017</td>\n",
       "      <td>-10.793410</td>\n",
       "      <td>16.422295</td>\n",
       "      <td>-479.978534</td>\n",
       "      <td>360</td>\n",
       "      <td>302</td>\n",
       "      <td>1</td>\n",
       "      <td>414</td>\n",
       "      <td>490.061797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>png_downsampled_xy002.png</td>\n",
       "      <td>502.884212</td>\n",
       "      <td>478.987800</td>\n",
       "      <td>399.134267</td>\n",
       "      <td>-576.638192</td>\n",
       "      <td>-0.392219</td>\n",
       "      <td>24.027846</td>\n",
       "      <td>-18.493505</td>\n",
       "      <td>16.364915</td>\n",
       "      <td>-478.132957</td>\n",
       "      <td>360</td>\n",
       "      <td>302</td>\n",
       "      <td>2</td>\n",
       "      <td>413</td>\n",
       "      <td>487.370424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>png_downsampled_xy003.png</td>\n",
       "      <td>477.298748</td>\n",
       "      <td>478.279647</td>\n",
       "      <td>376.156835</td>\n",
       "      <td>-490.232893</td>\n",
       "      <td>-0.057176</td>\n",
       "      <td>12.348837</td>\n",
       "      <td>-16.587044</td>\n",
       "      <td>14.802872</td>\n",
       "      <td>-432.497906</td>\n",
       "      <td>360</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>412</td>\n",
       "      <td>485.857434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Filenames          ox          oy          oz          ux  \\\n",
       "0  png_downsampled_xy000.png  494.408054  334.373789  388.076803 -602.175069   \n",
       "1  png_downsampled_xy001.png  494.301132  481.155443  414.635889 -584.046991   \n",
       "2  png_downsampled_xy002.png  502.884212  478.987800  399.134267 -576.638192   \n",
       "3  png_downsampled_xy003.png  477.298748  478.279647  376.156835 -490.232893   \n",
       "\n",
       "         uy         uz         vx         vy          vz  width  height  nr  \\\n",
       "0 -0.052537  14.651203 -10.271103  16.361331 -478.207237    360     302   0   \n",
       "1 -0.133129  16.613017 -10.793410  16.422295 -479.978534    360     302   1   \n",
       "2 -0.392219  24.027846 -18.493505  16.364915 -478.132957    360     302   2   \n",
       "3 -0.057176  12.348837 -16.587044  14.802872 -432.497906    360     302   3   \n",
       "\n",
       "   vole_depths      depths  \n",
       "0          415  342.371957  \n",
       "1          414  490.061797  \n",
       "2          413  487.370424  \n",
       "3          412  485.857434  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the reference csv as a Pandas DataFrame\n",
    "filename = path_to_PrV_Reference + \"DeepSlice_PrV_Reference.csv\"\n",
    "DeepSlice_PrV = pd.read_csv(filename, header=0)\n",
    "DeepSlice_PrV.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a182c9e0-2236-4517-9d1a-d51c713a9941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filenames</th>\n",
       "      <th>ox</th>\n",
       "      <th>oy</th>\n",
       "      <th>oz</th>\n",
       "      <th>ux</th>\n",
       "      <th>uy</th>\n",
       "      <th>uz</th>\n",
       "      <th>vx</th>\n",
       "      <th>vy</th>\n",
       "      <th>vz</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>depths</th>\n",
       "      <th>vole_depths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E1572_10x_stitch_CH2-downsized.png</td>\n",
       "      <td>439.274002</td>\n",
       "      <td>283.198959</td>\n",
       "      <td>350.450287</td>\n",
       "      <td>-475.870483</td>\n",
       "      <td>-12.129413</td>\n",
       "      <td>-42.959049</td>\n",
       "      <td>25.740665</td>\n",
       "      <td>-25.492914</td>\n",
       "      <td>-363.919922</td>\n",
       "      <td>300</td>\n",
       "      <td>205</td>\n",
       "      <td>265.577824</td>\n",
       "      <td>228.699699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Filenames          ox          oy          oz  \\\n",
       "0  E1572_10x_stitch_CH2-downsized.png  439.274002  283.198959  350.450287   \n",
       "\n",
       "           ux         uy         uz         vx         vy          vz  width  \\\n",
       "0 -475.870483 -12.129413 -42.959049  25.740665 -25.492914 -363.919922    300   \n",
       "\n",
       "   height      depths  vole_depths  \n",
       "0     205  265.577824   228.699699  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DeepSlice_wDepth = interpolate_depths(DeepSlice_PrV, DeepSlice_rawOutput)\n",
    "DeepSlice_wDepth.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "47a42ea1-31d3-4569-ba86-7e3a640d6d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filenames</th>\n",
       "      <th>ox</th>\n",
       "      <th>oy</th>\n",
       "      <th>oz</th>\n",
       "      <th>ux</th>\n",
       "      <th>uy</th>\n",
       "      <th>uz</th>\n",
       "      <th>vx</th>\n",
       "      <th>vy</th>\n",
       "      <th>vz</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>vole_depths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E1572_10x_stitch_CH2-downsized.png</td>\n",
       "      <td>410.337227</td>\n",
       "      <td>228.699699</td>\n",
       "      <td>335.856627</td>\n",
       "      <td>-457.044731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-46.37532</td>\n",
       "      <td>26.22191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-326.076668</td>\n",
       "      <td>300.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>228.699699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Filenames          ox          oy          oz  \\\n",
       "0  E1572_10x_stitch_CH2-downsized.png  410.337227  228.699699  335.856627   \n",
       "\n",
       "           ux   uy        uz        vx   vy          vz  width  height  \\\n",
       "0 -457.044731  0.0 -46.37532  26.22191  0.0 -326.076668  300.0   205.0   \n",
       "\n",
       "   vole_depths  \n",
       "0   228.699699  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_list = []\n",
    "u_list=[]\n",
    "v_list=[]\n",
    "for alignment in DeepSlice_wDepth.iterrows():\n",
    "    section = alignment[1][[\"ox\", \"oy\", \"oz\", \"ux\", \"uy\", \"uz\", \"vx\", \"vy\", \"vz\",\"vole_depths\"]]\n",
    "    o_rot, u_rot, v_rot = adjust_size_center(DeepSlice_PrV, section)\n",
    "   \n",
    "    o_list.append(o_rot)\n",
    "    u_list.append(u_rot)\n",
    "    v_list.append(v_rot)\n",
    "    \n",
    "DeepSlice_voleCoords = substitute_PrVRef_values(DeepSlice_wDepth,o_list,u_list,v_list)\n",
    "DeepSlice_voleCoords.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e89f9d8-e15e-443f-949d-f3b29908a3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to DeepSlice_PrV_adjustment/Sample_Images/DeepSlice_PrV_Sample_10x_CH2_adjusted.json\n",
      "saving to DeepSlice_PrV_adjustment/Sample_Images/DeepSlice_PrV_Sample_10x_CH2_adjusted.xml\n"
     ]
    }
   ],
   "source": [
    "# Set output path and file name without extension (.xml or .json)\n",
    "output_path = path_to_images\n",
    "filename = 'DeepSlice_PrV_Sample_10x_CH2_adjusted'\n",
    "\n",
    "write_QUINT_JSON(DeepSlice_voleCoords, output_path + filename, \"prerelease_1.0.0\", \"PrV.cutlas\")\n",
    "write_QuickNII_XML(DeepSlice_voleCoords, output_path + filename, \"prerelease_1.0.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f94b08e-552f-4708-8687-59652987f083",
   "metadata": {},
   "source": [
    "* Now, you should have both .json and .xml files with the appropriate depth for the PrV version of QuickNII\n",
    "* Before getting started, watch this video from QUINT to familiarize yourself with their pipeline: https://quint-workflow.readthedocs.io/en/latest/QUINTintro.html\n",
    "* Open QuickNII (QuickNII.exe)\n",
    "    * In the top right, click Manage Data\n",
    "        * Load\n",
    "            * Select your json or xml descriptor for your images\n",
    "            * Open\n",
    "        * You now have a list of images. On the righthand side, there will be a red ? or a green !, idicating whether the section has been anchored. If you have used DeepSlice, this will be green by default.\n",
    "        * click on one of the images to get started with manual adjustments\n",
    "    * Back in the main QuickNII window you will see a range of controls. \n",
    "        * On the left, you can toggle between the section and the reference template. I recommend using the \"Template\" version for adjustment, which can be selected from the drop-down on the top left.\n",
    "        * On the right, you will see cross-sections of the reference brain, with sliders that allow you to adjust position.\n",
    "        * On the bar above the image, you can see the coordinates of your cursor in atlas space, as well as buttons to shift the section up/down/left/right, as well as adjust the width and height.\n",
    "    * Make fine adjustments until you are satisfied. Select \"Store\" and return to the \"Manage data\" menu. If you have multiple sections, the program will update the other sections based off of the adjustments you've made. Typically it only takes a few sections anchored at the beginning and end of a series for the rest of the sections to be registered well. It is recommended to wait until sections have been anchored before finding the cutting angles that work best for every section.\n",
    "* Select Save JSON to export a new JSON file for use in Visualign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e545041-bb55-401a-a27c-e0524c87559a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
